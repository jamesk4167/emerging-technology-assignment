{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](pictures/Mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mnist dataset contains 70,000 examples of handwritten letters. There are 60,000 Training sets for data and 10,000 for testing. The images have been normalized and centred in fixed size images.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is helpful for people who want to learn about using Machine learning algorithms, without the need for preprocessing and normalising all of the data, which can be a time consuming process when the data sets are large, ie 70,000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Training set images](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz)<br/>\n",
    "[Training Set Labels](http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz)<br/>\n",
    "[Test Set Images](http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz)<br/>\n",
    "[Test Set Labels](http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz)<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# adapted from: https://docs.python.org/3/library/gzip.html\n",
    "\n",
    "import gzip\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    file_content = f.read()\n",
    "    \n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import keras as kr\n",
    "import sklearn.preprocessing as pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the data we can print the first 4 bytes in order to ensure we are reading the right file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00\\x00\\x08\\x03'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each arguement has 4 bytes, this is where I got the 16 from for the For loop below\n",
    "file_content[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "image = ~np.array(list(file_content[16:800])).reshape(28,28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading in the first image in the set we can display it using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f6df7cc18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above image we can see that the images are arranged into 784 bytes. After reading in the first 16 bytes of the training set, all of the next bytes are part of the image so just need to loop through them after this and save them to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    Traininglabels = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "int.from_bytes(Traininglabels[8:9], byteorder=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So from reading in the first image and the second image we can see that the images and labels match up, lets just try with the second image to make sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = ~np.array(list(file_content[800:1584])).reshape(28,28).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f6e018a20>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image2, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int.from_bytes(Traininglabels[9:10], byteorder=\"big\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great so this proves to us that the images and labels match up also, both Images are centred and so proves to us that after the opening 16 bytes the images are all contained inside 28 by 28 arrays or arrays of size 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving images to system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "    \n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "\n",
    "#StartingBytes is where the images start and ImageSizeInBytes is the how far after the first 16 bytes \n",
    "\n",
    "\n",
    "StartingBytes = 16\n",
    "AfterFirstImageSizeInBytes = 800\n",
    "#Decided to use a for loop to read the images\n",
    "for i in range(10):\n",
    "    images = ~np.array(list(train_img[StartingBytes :AfterFirstImageSizeInBytes])).reshape(28,28).astype(np.uint8)\n",
    "    StartingBytes += 784\n",
    "    AfterFirstImageSizeInBytes += 784\n",
    "    #cv2.imwrite('training' + str(i) + '.png', images )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More efficent way to read in images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However as we learned in class this is not the most efficent way to read the images so instead we can use a numpy trick to download them by simply re-arranging  the images line above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images2 = ~np.array(list(train_img[16 :])).reshape(60000,28,28).astype(np.uint8)\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that I have showed how to read in the files we can go on to discuss our neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous notebook(Iris_dataset) we are using keras here to create our neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images for testing\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "# Read in labels for testing\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = kr.models.Sequential()\n",
    "\n",
    "model.add(kr.layers.Dense(units = 512, activation = 'linear', input_dim = 784))\n",
    "model.add(kr.layers.Dense(units = 512, activation = 'relu'))\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 55s 919us/step - loss: 0.5099 - acc: 0.84401s - loss: 0.5158\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 52s 863us/step - loss: 0.2217 - acc: 0.9315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17f6dfd0940>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs, outputs, epochs=2, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9462"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_img[5:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17f02662400>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_img[5].reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside of this notebook I have examined the Mnist dataset, and showed how it can be successfully manipulated and saved to the system, I have also given a brief description of keras."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
